---
layout: post
title: Deep Learning Book Chapter 3
author: dg4271
categories: Deep-Learning
excerpt: Probability and Information Theory
use_math: true
---

# Probability and Information Theory

[Deep learning book - Chapter 3](http://www.deeplearningbook.org/contents/prob.html)

$$
x
$$

$x$

- **확률 이론**은 **불확실성**을 표현하는 수학적 틀이다. 인공지능 응용 분야에서 확률 이론을 크게 두 가지 이유로 사용한다. 
    + 확률 법칙은 AI 시스템이 어떻게 추론되어야 하는지 알려주므로, 확률 이론을 사용하여 도출 된 다양성 표현을 계산하거나 근사화하는 알고리즘을 설계하게 된다.
    + 확률 및 통계학을 사용하여 AI 시스템의 동작을 이론적으로 분석 할 수 있다.
- 확률 이론이 불확실성을 표현하고 그 존재를 판단할 수 있게한다면, 확률 분포에서 불확실성의 양을 정량화 할 수 있게 해주는 것은 **정보 이론**이다.
### 3.1 Why Probability?
- 많은 컴퓨터 분야에서는 결정적론적이고 확실성을 갖는 실체들을 다룬다. 그리고 프로그래머는 각 기계 명령어가 오류를 일으키지 않는다고 가정한다.
- 그러나 기계 학습에서는 항상 불확실한 양을 다루어야하고, 때때로는 비 결정적(stochastic, non-deterministic) 양을 다루기도 한다.
- 즉 어떤 proposition도 절대적으로 참이거나 반드시 발생하는 것을 보장하는게 어렵다는 것이다.
- 불확실성은 아래와 같은 이유에서 발생한다.
    + Inherent stochasticity; 예를 들어 양자 역학에서 원자핵 입자의 역학을 확률론적으로 생각하는 것, 카드가 무작위로 섞인 상태를 들 수 있다. 이러한 시스템들 에서는 필연적으로 불확실성이 개입되어 있다.
    + Incomplte observability; 만약 시스템 자체는 결정론적이라고 하더라도 그 시스템의 보든 것을 관찰할 수 없을 때에는 stochastic이 드러난다. 예를 들어 Monty Hall 문제에서 3개의 문중에서 두 문은 염소로 이어지고 나머지 하나의 문만 차로 연결된다. 이때 문제의 결과는 결정론적 이지만 참가자의 관점에서 결과는 불확실하다.
    + Incomplete modeling; 우리가 관찰한 정보 중 일부를 버려야하는 모델을 사용할 때 불확실성을 초래한다. 책의 예제에서는 물체들의 위치를 관측하는 로봇이 해당 물체들의 미래 위치를 예측할 때 공간을 이산화하는 작업을 하고, 이산화가 물체들의 위치를 불확실하게 만든다고 합니다. 예측을 위한 모델은 가장 높은 가능성을 갖는 것으로 예측하기 때문에 이러한 것을 불확실성이라고 하는 것으로 생각할 수 있다.
- 확실하지만 복잡한 방법보다는 불확실하지만 간단한 방법이 practical 하다.
- 원래 확률 이론은 frequencies of events, 즉 어떤 사건이 참일 확률이 p라는 것은 그 사건이 무수히 많이 일어났을때의 참인 비율이 p%라는 것을 말한다. -> Frequentist probability
- 그러나 기계 학습에서 사용하는 확률은 degree of belief, 즉 의사가 환자를 진단하는 상황에서 병에 걸릴 확률을 p라고 하는 것을 의미한다. 이 때 환자는 병이라는 말을 p% 정도 믿을 것이다. -> Bayesian probability.
- 확률을 불확실성을 다루도록 확장한 logic으로 생각할 수 있다. 즉 확률 이론으로 어떤 likilihood of propositions가 주어졌을 때 다른 likelihood of a proposition이 참임을 증명하는 formal rules를 제공할 수 있다.

### 3.2 Random Variables
- 여러 값을 임의로 갖는 변수를 확률 변수(random variables)라고 한다.
- 확률 변수 $x$가 갖는 값들을 \(x_1\), \(x_2\) 과 같이 표기하며, 값을 벡터의 형태로 가질 수도 있다.

### 3.3 Probability Distributions
- 확률 분포는 하나 혹은 여러 개의 확률 변수들이 가능한 상태를 취할 가능성을 보여주는 description이다. 

    ####3.3.1 Discrete Variables and Probabiltiy Mass Functions
    + 이산 확률 변수의 분포는 **probability mass function (PMF)**로 묘사한다. 수학적으로는 주로 \(P(x)\)로 표현.
    + \(P(x)\)는 x=\(x\)인 확률을 의미한다. 어떤 확률 변수 x가 확률 분포 \(P(x)\)를 따르는 것을 x~\(P(\)x\()\)로 표기
    + 대표적인 예로 **uniform distribution**이 있다.
        * \(P(\)x\(=x_i) = \frac{1}{k}\)
        * 모든 \(i\)에 대하여 확률이 \(\frac{1}{k}\)로 동일
        * \(\sum_{i} P(x=x_i)=\sum_{i}\frac{1}{k}=\frac{k}{k}=1\)

    ####3.3.2 Continuous Variables and Probability Density Functions
    + 연속 확률 변수의 분포는 **probability density function (PDF)**로 묘사한다.
    + 연속 확률 분포에서는 특정 상태의 확률을 계산할 수 없고, 확률 변수 x가 [a,b] 사이일 확률로 구해야 한다.
        * \(\int_{[a,b]} p(x)dx\)의 의미는, 확률 변수 x가 [a,b]일 확률

### 3.4 Marginal Probability
- 여러 확률 변수 집합 중 부분 집합의 확률 분포를 알고 싶을 때, **marginal probability** 분포를 사용한다.
- 두 확률 변수 x,y의 확률 분포 \(P(x,y)\)에서 \(P(x)\)를 **sum rule**을 통해 얻을 수 있다.
    + \(\forall x \in x, P(x=x)=\sum_{y} P(x=x, y=y)\)
    + 연속 확률 변수에 경우에는, \(p(x)=\int p(x,y)dy\)을 사용   

### 3.5 Conditional Probability
- 사건 x가 일어난 상황에서 사건 y가 일어날 확률
- \(P(y=y|x=x)=\frac{P(y=y, x=x)}{P(x=x)}\)

### 3.6 The Chain Rule of Conditional Probabilities
- 어떤 joint probability distribution을 conditional distributions로 나눌 수 있다.
    + \(P(a,b,c)=P(a|b,c)P(b|c)P(c)\)
    + **chain rule** or **product rule**을 이용하여 위와 같이 전개할 수 있다. 

### 3.7 Independence and Conditional Independence 
- 두 확률 변수 x,y는 아래와 같을 때 **independent**하다. 
    + \(\forall x \in x, y \in y, p(x=x,y=y)=p(x=x)p(y=y)\)
- 두 확률 변수 x,y는 아래와 같이 확률 변수 z가 주어졌을 때 **conditionally independent**하다.
    + \(\forall x \in x, y \in y, z \in z, p(x=x,y=y|z=z)=p(x=x|z=z)p(y=y|z=z)\)

### 3.8 Expectation, Variance and Covariance
- **Expectation** or **expected value**은 어떤 데이터간의 함수 \(f(x)\) 가 확률 분포 \(P(x)\)를 따를 때, 아래와 같이 표현할 수 있다.

$$ E[f(x)] = \sum_{x} P(x)f(x) $$
$$ E[f(x)] = \int_{x} P(x)f(x) $$

- Expectation은 곧 어떤 함수가 특정 확률 분포를 따를 때, 평균정도로 기대할 수 있는 값이라고 생각할 수 있다.
- **Variance**는 \(f(x)\) 값들이 \(E[f(x)]\) 값들과 떨어져 있는 정도로 생각할 수 있다. 즉 variance가 클 수록 \(E[f(x)]\)와 멀게 데이터들이 분포한다.
- 보통 variance보다는 제곱근 값인 **standard deviation**을 사용한다.
- **Covariance**는 두 데이터가 선형적으로 얼마나 관계가 있는지를 보여준다.
- Covariance가 양수인 경우 두 데이터 모두 평균 보다 높은 값을 보여주는 경향이 있다는 것이며 음수인 경우 한 데이터는 평균 보다 높은 경향인 반면 다른 데이터는 평균 보다 낮은 경향을 보일 때, 발생한다. 즉 양수일 수록 두 데이터는 선형 관계가 있는 것이다.
- Covariance는 독립/종속 개념과도 관계가 있다. non-zero covariance는 두 데이터가 종속적임을 보여준다. 그리고 독립인 두 데이터는 zero covaiance를 갖는다. 이 때 zero vovariance라고 해서 두 데이터가 독립임을 보장해주지는 않는다. 

### 3.9 Common Probability Distributions

#### 3.9.1 Bernoulli Distribution
- 베르누이 분포. 확률 변수 x가 0과 1만 갖는다고 했을 때의 확률 분포는 아래와 같다.
$$ P(x=1) = \phi $$
$$ P(x=0) = 1-\phi $$
$$ P(x=x) = \phi^x(1-\phi)^{1-x} $$
$$ E[x] = \phi $$
$$ Var(x) = \phi(1-\phi) $$
- 이항 분포에 대한 공액(conjugacy) 분포로 Beta distribution을 사용한다 (PRML 책의 Beta distribution 참고할 것.)

#### 3.9.2 Multinoulli Distribution
- categorical distribution 이라고도 함
- 베르누이 분포를 k차원으로 확장한 것, 공액 분포로 Dirichlet distribution을 사용한다.

$$ p(x|\mu)=\prod_{k=1}^K \mu_{k}^{x_{k}} $$


#### 3.9.3 Gaussian Distribution
- 정규 분포(normal distribution)
- 평균과 표준 편차를 파라미터로 갖는 확률 분포.
- 편리함을 위하여 $ \beta = \frac{1}{\sigma^2} $ 와 같이 정의한 **precision**을 자주 사용한다.
- 데이터에 대한 사전 지식이 전혀 없을 경우 정규 분포를 따른다고 생각해보는 것이 기본적인 생각이다.
    + 거의 대부분의 분포가 정규 분포에 따르기 때문 (중심 극한 정리: 동일한 확률 분포를 가진 독립 확률 변수 n개의 평균의 분포는 n이 적당히 크면 정규분포에 따른다는 정리)
    + 정규 분포는 동일한 분산을 갖는 다른 모든 확률 분포 중에서 가장 불확실성의 양이 최대인 특성을 가진다. 따라서 사전 지식이 전혀 없을 때 정규 분포르 선택하는 것은 합리적이다.
- Multivariate normal distribution: n차원의 정규 분포

#### 3.9.4 Exponential and Laplace Distributions
- 딥러닝에서는 종종 sharp point(x=0)에서의 확률 분포도 구하고 싶을 때가 있다. 이 경우에는 **Exponential distribution** 혹은 **Laplace distribution**을 사용할 수 있음

#### 3.9.5 The Dirac Distribution and Empirical Distribution
- 한 점에 모든 확률 분포가 몰려 있는 것을 표현하기 위하여 **Dirac delta function $\delta(x) $**를 사용한다.
$$ p(x) = \delta(x-\mu) $$
- Empirical distribution,, 어렵다.


#### 3.9.6 Mixtures of Distributions
- 상대적으로 간단한 확률 분포들을 합하여 생성한 richer distribution.
- 대표적으로, 위의 Empirical Distribution와 **Gaussian mixture**가 Mixture distribution 이다.

### 3.10 Useful Properites of Common Functions
- 딥러닝 모델에 자주 사용되는 함수들의 대한 설명.
- **Logistic sigmoid**
$$ \sigma(x)=\frac{1}{1+exp(-x)} $$
    + logistic sigmoid는 (0,1)의 범위를 갖는 특성 갖기 때문에, 베르누이 분포의 파라미터 $\phi$ 를 생성할 때 주로 쓰인다.

- **Softplus**
$$ \zeta(x)=log(1+exp(x)) $$
    + softplus 함수는 (0,$\infty$)의 범위를 갖기 때문에, 정규 분포의 파라미터 $\beta, \sigma $를 생성하는데 주로 쓰인다.

### 3.11 Bayes' Rule
$$ P(x|y) = \frac{P(x)P(y|x)}{P(y)} $$
- 조건부 확률을 이용한 수식으로, $ P(y|x) $ 를 알 때 $ P(x|y) $를 알고 싶은 상황에서 유용하게 쓰인다.

### 3.12 Technical Details of Continuous Variables
- 연속 확률 변수, 확률 밀도 함수 등을 명확히 이해하기 위해서는 확률 이론 분야의 한 가지인 **measure theory**가 유용하다. 이 책에서는 자세히 다루지 않고 개념 몇가지 정도만 소개하고 있다.
- **Measure zero**
    + n차원의 실수 공간에 대부분의 점에만 어떤 이론을 적용하고, corner 점에 대해서는 적용하고 싶지 않을 때가 있다. 이 때 corner 점들을 measure zero를 이용하여 묘사할 수 있다.
    + 개념적으로 2차원 공간에서는 선은 measure zero이고, 다각형인 경우 positive measure, 하나의 점은 measure zero이다.
- **Almost everywhere**
    + measure zero인 집합을 제외하고 거의 모든 공간에 대하여 성립하는 어떤 개념이 있을 때, 위의 표현을 사용한다.
    + Measure zero 부분을 무시해도 안전할 경우임을 뜻하기도 한다.

- $ y=g(x) $일 때, $p_y(y)=p_x(g^{-1}(y)) $는 쉽게 생각하는 오류이다.
- $ p_y(y) = p_x(g^{-1}(y)) |{\frac{\delta x}{\delta g(x)}}| $ 가 올바른 표현.
- 다차원으로 일반화할 경우에는  **Jacobian matrix**의 determinant를 사용한다. 

$$ J_{i,j} = \frac{\delta x_i}{\delta y_j} $$
$$ p_x(x) = p_y(g(x))|\det(\frac{\delta g(x)}{\delta x})| $$

### 3.13 Information Theory
- 머신 러닝 분야에서는 확률 분포를 characterize 하거나 확률 분포 간의 유사도를 정량화 하기 위하여 정보 이론을 사용한다.
- 정보 이론의 직관은, 잘 일어나지 않는 사건의 발생이 잘 일어나는 사건의 발생 보다 더 informative하다는 것이다. 아래와 같이 공식화 할 수 있음
    + 일어날 것이 보장 된 사건은 information 이 없다.
    + 덜 일어나는 사건일 수록 더 많은 information을 갖는다.
    + 독립적인 사건들에 대하여 information 양을 더할 수 있다.
- 위를 잘 만족하는 수식을 정의: **self-information**
    + 이 책에서는 로그 밑을 $e$로 사용한다. 이는 사건의 확률이 $\frac{1}{e}$인 경우 얻어지는 정보의 양이 **1 nat**임을 말한다. (nat: 정보의 단위)
$$ I(x) = -logP(x) $$
- 전체 확률 분포의 정보량 정량화: **Shannon entropy**
    + 하나의 사건이 특정 분포를 갖을 때, 정보량의 기대값은 다음과 같다.
    + 분포의 출력이 확정적이면 샤년 엔트로피는 낮고, 반대의 경우 높다.
$$ H(x)=E_{x~P}[I(x)]=-E_{x~P}[logP(x)] $$
- 두 확률 분포가 얼마나 다른지를 측정: **Kullback-Leibler (KL) divergence**
    + 두 분포가 동일하다면 KL divergence 값은 0
$$ D_{KL}(P||Q) = E_{x~P}[log\frac{P(x)}{Q(x)} = E_{x~P}[logP(x)-logQ(x)] $$

### 3.14 Structured Probabilistic Models
- 머신 러닝 알고리즘은 종종 많은 수의 랜덤 변수를 이용하는데, 이 때 하나의 랜덤 변수와 직접적으로 관계있는 변수는 상대적으로 적다.
- 때문에 이러한 관계를 효율적으로 표현하기위하여 아래와 같이 곱으로 표현한다.
$$ p(a,b,c) = p(a)p(b|a)p(c|b) $$
    + 위와 같이 factorization 함으로써, 전체 분포를 표현할 때 필요한 파라미터의 수를 줄일 수 있게 된다. 
    + 또한 이러한 것을 그래프로 표현하고 **structured probabilistic model** 또는 **graphical model**이라고 부른다.
    + Directed 와 Undirected model이 있으며, 이러한 그래프는 확률 분포를 효과적으로 표현/묘사하는 언어라고 생각하면 된다.

- **Directed** model
    + 조건부 확률 분포로 분할 했을 경우 사용
    + $p(x)=\prod_i p(x_i|Pag(x_i))$

- **Undirected** model
    + 함수의 집합으로 분할 했을 경우 사용, 
    + $ p(x) = \frac{1}{Z}\prod_i\phi^(i)(C^(i)). $
    + undirected model에서는 각 노드를 clique라 부르며 각각의 노드에 대한 함수 $ \phi^(i)(C^(i)) $가 정의 되어 있다.


